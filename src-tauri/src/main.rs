#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

use tauri::{Manager, RunEvent};
use tauri_plugin_shell::ShellExt;
use tauri_plugin_shell::process::CommandChild;
use std::path::Path;
use std::fs;
use std::env;
use std::sync::{Arc, Mutex};
use std::collections::{HashSet, HashMap};

// --- Rig & OpenAI ---
use rig::providers::openai::Client;
use rig::embeddings::{EmbeddingsBuilder, Embed, TextEmbedder, EmbedError};
use rig::client::{ProviderClient, EmbeddingsClient};

// --- SurrealDB ---
use surrealdb::engine::local::{Db, RocksDb};
use surrealdb::Surreal;
use surrealdb::sql::Thing;

// --- Utils ---
use serde::{Serialize, Deserialize, de::DeserializeOwned};
use serde_json::Value as JsonValue;
use pdf_extract::extract_text;
use anyhow::Context;
use dotenvy::dotenv;
use chrono::{DateTime, Utc};
use uuid::Uuid;

// ---------------------------------------------------------
// 1. ë°ì´í„° êµ¬ì¡°ì²´ ì •ì˜
// ---------------------------------------------------------
#[derive(Debug, Deserialize)]
struct RawRecord {
    id: Thing,
    #[serde(flatten)]
    content: HashMap<String, JsonValue>,
}

// Layer 3: ì‚¬ê±´ (Event) - ì–¸ì œ ë°ì´í„°ë¥¼ ë„£ì—ˆëŠ”ê°€?
#[derive(Debug, Serialize, Deserialize)]
struct EventNode {
    id: Option<Thing>,
    summary: String,
    created_at: DateTime<Utc>,
}

// Layer 1: ë¬¸ì„œ (Document) - íŒŒì¼ ê·¸ ìì²´
#[derive(Debug, Serialize, Deserialize)]
struct DocumentNode {
    id: Option<Thing>,
    filename: String,
    created_at: DateTime<Utc>,
}

// Layer 1-2: ì²­í¬ (Chunk) - ì‹¤ì œ ë‚´ìš©ê³¼ ë²¡í„°
#[derive(Debug, Serialize, Deserialize)]
struct ChunkNode {
    id: Option<Thing>,
    content: String,
    embedding: Vec<f32>,
    page_index: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct RigDoc {
    id: String,
    content: String,
}

// Rigì˜ Embed trait êµ¬í˜„ (ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë°˜í™˜)
impl Embed for RigDoc {
    fn embed(&self, embedder: &mut TextEmbedder) -> Result<(), EmbedError> {
        embedder.embed(self.content.clone());
        Ok(())
    }
}

// ---------------------------------------------------------
// Graph Visualize Structure
// ---------------------------------------------------------
#[derive(Serialize, Debug)]
struct GraphNode {
    id: String,
    group: String, // ìƒ‰ìƒ êµ¬ë¶„ì„ ìœ„í•´ (event, document, chunk)
    label: String, // í™”ë©´ì— í‘œì‹œí•  ì´ë¦„
    val: usize,    // ë…¸ë“œ í¬ê¸°
}

#[derive(Debug, Deserialize)]
struct EdgeRecord {
    id: Thing,
    #[serde(rename = "in")] // Rust ì˜ˆì•½ì–´ 'in' íšŒí”¼
    in_: Thing,
    out: Thing,
}

#[derive(Serialize, Debug)]
struct GraphLink {
    source: String,
    target: String,
}

#[derive(Serialize, Debug)]
struct GraphData {
    nodes: Vec<GraphNode>,
    links: Vec<GraphLink>,
}

fn json_val_to_id(val: Option<&JsonValue>) -> String {
    match val {
        Some(JsonValue::String(s)) => s.clone(),
        Some(JsonValue::Object(o)) => {
            // { tb: "table", id: "uuid" } í˜•íƒœì¼ ë•Œ
            let tb = o.get("tb").and_then(|v| v.as_str()).unwrap_or("");
            let id = o.get("id").map(|v| v.to_string().replace("\"", "")).unwrap_or_default();
            format!("{}:{}", tb, id)
        },
        _ => String::new(),
    }
}

#[tauri::command]
async fn fetch_graph_data(state: tauri::State<'_, AppState>) -> Result<GraphData, String> {
    println!("ğŸš€ [Graph] ë°ì´í„° ì¡°íšŒ ì‹œì‘ (Generic Mode)");
    let db = &state.db;
    
    let mut nodes = Vec::new();
    let mut raw_links = Vec::new();
    let mut valid_node_ids = HashSet::new();

    // ğŸ› ï¸ ì œë„¤ë¦­ ì¿¼ë¦¬ ì‹¤í–‰ í•¨ìˆ˜ (T: ì–´ë–¤ êµ¬ì¡°ì²´ë¡œë„ ë³€í™˜ ê°€ëŠ¥)
    async fn exec_query<T: DeserializeOwned>(db: &Surreal<Db>, sql: &str, table_name: &str) -> Result<Vec<T>, String> {
        let mut response = db.query(sql).await.map_err(|e| {
            format!("âŒ [{}] ì¿¼ë¦¬ ì‹¤íŒ¨: {}", table_name, e)
        })?;

        let items: Vec<T> = response.take(0).map_err(|e| {
            format!("âŒ [{}] íŒŒì‹± ì‹¤íŒ¨: {}", table_name, e)
        })?;

        println!("   âœ… [{}] ì¡°íšŒ ì„±ê³µ: {} ê±´", table_name, items.len());
        Ok(items)
    }

    // -------------------------------------------------------------
    // 1. ë…¸ë“œ ì¡°íšŒ (RawRecord ì‚¬ìš©)
    // -------------------------------------------------------------
    
    // (1) Event
    let events: Vec<RawRecord> = exec_query(db, "SELECT * FROM event", "Event").await?;
    for r in events {
        let id_str = r.id.to_string();
        valid_node_ids.insert(id_str.clone());
        nodes.push(GraphNode {
            id: id_str,
            group: "event".to_string(),
            label: "Session".to_string(),
            val: 20,
        });
    }

    // (2) Document
    let docs: Vec<RawRecord> = exec_query(db, "SELECT * FROM document", "Document").await?;
    for r in docs {
        let id_str = r.id.to_string();
        let filename = r.content.get("filename").and_then(|v| v.as_str()).unwrap_or("Unknown").to_string();
        
        valid_node_ids.insert(id_str.clone());
        nodes.push(GraphNode {
            id: id_str,
            group: "document".to_string(),
            label: filename,
            val: 10,
        });
    }

    // (3) Chunk
    let chunks: Vec<RawRecord> = exec_query(db, "SELECT id, page_index FROM chunk", "Chunk").await?;
    for r in chunks {
        let id_str = r.id.to_string();
        let page = r.content.get("page_index").and_then(|v| v.as_u64()).unwrap_or(0);
        
        valid_node_ids.insert(id_str.clone());
        nodes.push(GraphNode {
            id: id_str,
            group: "chunk".to_string(),
            label: format!("p.{}", page),
            val: 5,
        });
    }

    // -------------------------------------------------------------
    // 2. ì—£ì§€ ì¡°íšŒ (EdgeRecord ì‚¬ìš© !!!)
    // -------------------------------------------------------------
    // ì—¬ê¸°ì„œ ì œë„¤ë¦­ íƒ€ì…ì„ <EdgeRecord>ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
    
    // (4) Imported Edges
    let imported_edges: Vec<EdgeRecord> = exec_query(db, "SELECT * FROM imported", "Imported").await?;
    for edge in imported_edges {
        // Thing íƒ€ì…ì„ ë°”ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜ (.to_string())
        let source = edge.in_.to_string();
        let target = edge.out.to_string();
        
        raw_links.push(GraphLink { source, target });
    }

    // (5) Contains Edges
    let contains_edges: Vec<EdgeRecord> = exec_query(db, "SELECT * FROM contains", "Contains").await?;
    for edge in contains_edges {
        let source = edge.in_.to_string();
        let target = edge.out.to_string();
        
        raw_links.push(GraphLink { source, target });
    }

    // -------------------------------------------------------------
    // 3. í•„í„°ë§ ë° ë°˜í™˜
    // -------------------------------------------------------------
    let links: Vec<GraphLink> = raw_links
        .into_iter()
        .filter(|link| valid_node_ids.contains(&link.source) && valid_node_ids.contains(&link.target))
        .collect();

    println!("ğŸ [Graph] ìµœì¢… ë°˜í™˜: Nodes {}, Links {}", nodes.len(), links.len());
    Ok(GraphData { nodes, links })
}

// ---------------------------------------------------------
// 2. AppState ì •ì˜
// ---------------------------------------------------------
struct AppState {
    db: Surreal<Db>,
    openai_client: Client,
}

// ---------------------------------------------------------
// 3. í—¬í¼ í•¨ìˆ˜
// ---------------------------------------------------------
fn load_pdf_content<P: AsRef<Path>>(file_path: P) -> anyhow::Result<String> {
    extract_text(file_path.as_ref())
        .with_context(|| format!("Failed to extract text from PDF: {:?}", file_path.as_ref()))
}

// [ì¶”ê°€ë¨] í…ìŠ¤íŠ¸ ì²­í‚¹ í•¨ìˆ˜ (Chunking)
// text: ì „ì²´ í…ìŠ¤íŠ¸
// chunk_size: ìë¥¼ ê¸€ì ìˆ˜ (ì˜ˆ: 2000)
// overlap: ê²¹ì¹  ê¸€ì ìˆ˜ (ì˜ˆ: 200 - ë¬¸ë§¥ ëŠê¹€ ë°©ì§€)
fn chunk_text(text: &str, chunk_size: usize, overlap: usize) -> Vec<String> {
    let chars: Vec<char> = text.chars().collect();
    let mut chunks = Vec::new();
    let mut start = 0;

    while start < chars.len() {
        let end = std::cmp::min(start + chunk_size, chars.len());
        let chunk: String = chars[start..end].iter().collect();
        
        if !chunk.trim().is_empty() {
            chunks.push(chunk);
        }
        if end == chars.len() { break; }
        start += chunk_size - overlap;
    }
    chunks
}
// ---------------------------------------------------------
// Command: PDF ì²˜ë¦¬ ë° ì„ë² ë”©
// ---------------------------------------------------------
#[tauri::command]
async fn process_pdfs_graph(
    path: String,
    state: tauri::State<'_, AppState>,
) -> Result<String, String> {
    println!("ğŸ“‚ Graph Indexing ì‹œì‘: {}", path);
    let db = &state.db;

    // 1. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
    let embedding_model = state.openai_client.embedding_model("text-embedding-3-small");

    // 2. íŒŒì¼ ëª©ë¡ ì½ê¸°
    let directory_path = Path::new(&path);
    let entries = fs::read_dir(directory_path).map_err(|e| e.to_string())?;
    
    // 3. [Graph Layer 3] Event ë…¸ë“œ ìƒì„± ("Study Session")
    let session_id = Uuid::new_v4().to_string();
    let event_record: Option<EventNode> = db
        .create(("event", &session_id))
        .content(EventNode {
            id: None,
            summary: format!("PDF Import Session from {}", path),
            created_at: Utc::now(),
        })
        .await
        .map_err(|e: surrealdb::Error| e.to_string())?;
    
    let event_id = event_record.unwrap().id.unwrap(); // ìƒì„±ëœ Eventì˜ ID (event:uuid)

    let mut processed_count = 0;

    for entry in entries {
        let entry = entry.map_err(|e| e.to_string())?;
        let file_path = entry.path();

        if file_path.extension().and_then(|s| s.to_str()) == Some("pdf") {
            let filename = file_path.file_name().unwrap_or_default().to_string_lossy().to_string();
            println!("ğŸ“„ ì²˜ë¦¬ ì¤‘: {}", filename);

            // í…ìŠ¤íŠ¸ ì¶”ì¶œ
            let content = match extract_text(&file_path) {
                Ok(text) => {
                    println!("  âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ (ê¸¸ì´: {})", text.len());
                    text
                },
                Err(e) => {
                    // ì—ëŸ¬ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ë„ë¡ ìˆ˜ì •
                    println!("  âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {} (ê±´ë„ˆëœ€)", e);
                    continue; 
                }
            };

            if content.trim().is_empty() { continue; }

            // 4. [Graph Layer 1] Document ë…¸ë“œ ìƒì„±
            println!("  ğŸ’¾ DBì— Document ë…¸ë“œ ìƒì„± ì‹œë„...");
            let doc_uuid = Uuid::new_v4().to_string();
            let doc_record: Option<DocumentNode> = db
                .create(("document", &doc_uuid))
                .content(DocumentNode {
                    id: None,
                    filename: filename.clone(),
                    created_at: Utc::now(),
                })
                .await
                .map_err(|e| format!("DB Document ìƒì„± ì‹¤íŒ¨: {}", e))?; // ì—ëŸ¬ ë©”ì‹œì§€ êµ¬ì²´í™”
            
            // unwrap ì•ˆì „ì¥ì¹˜
            let doc_id = match doc_record {
                Some(rec) => rec.id.unwrap(),
                None => {
                    println!("  âŒ DB ë ˆì½”ë“œê°€ ë°˜í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
                    return Err("DB Record is None".to_string());
                }
            };
            println!("  âœ… Document ë…¸ë“œ ìƒì„± ì™„ë£Œ: {}", doc_id);

            // 5. [Edge] Event -> Document ì—°ê²° (RELATE êµ¬ë¬¸ ì‚¬ìš©)
            println!("  ğŸ”— ê´€ê³„ ì—°ê²° ì‹œë„: {} -> imported -> {}", event_id, doc_id);
            
            db.query("RELATE $event->imported->$doc SET time = time::now()")
                .bind(("event", event_id.clone()))
                .bind(("doc", doc_id.clone()))
                .await
                .map_err(|e| e.to_string())?
                .check() // ì—¬ê¸°ì„œ ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì§€ ì•Šê³  ì—ëŸ¬ ìœ ë¬´ë§Œ ì²´í¬í•©ë‹ˆë‹¤.
                .map_err(|e| e.to_string())?;

            println!("  âœ… ê´€ê³„ ì—°ê²° ì„±ê³µ: Event -> Document");

            // ì²­í‚¹ ë° ì„ë² ë”©
            let chunks = chunk_text(&content, 1000, 100); // ì²­í¬ ì‚¬ì´ì¦ˆ ì¡°ì ˆ
            println!("  ğŸ§© ì²­í‚¹ ì™„ë£Œ: {}ê°œ", chunks.len());

            // Rigë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„± (ì¼ê´„ ì²˜ë¦¬)
            // Rigì˜ Document íƒ€ì…ì„ ë§ì¶°ì¤˜ì•¼ í•¨
            let rig_docs: Vec<RigDoc> = chunks.iter().map(|c| {
                RigDoc {
                    id: "temp".to_string(), // ì„ë² ë”©ë§Œ ë½‘ì„ê±°ë¼ IDëŠ” ë¬´ê´€
                    content: c.clone(),
                }
            }).collect();

            if rig_docs.is_empty() { continue; }

            let embeddings_result = EmbeddingsBuilder::new(embedding_model.clone())
                .documents(rig_docs)
                .map_err(|e| format!("Rig ë¬¸ì„œ ë¹Œë“œ ì‹¤íŒ¨: {}", e))?
                .build()
                .await;

            let embeddings = match embeddings_result {
                Ok(emb) => {
                    println!("  âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ");
                    emb
                },
                Err(e) => {
                    println!("  âŒ OpenAI ì„ë² ë”© í˜¸ì¶œ ì‹¤íŒ¨: {}", e);
                    return Err(e.to_string());
                }
            };
            
            println!("  ğŸ’¾ Chunk ì €ì¥ ë° ì—°ê²° ì™„ë£Œ");

            // 6. [Graph Layer 1-2] Chunk ë…¸ë“œ ìƒì„± ë° ì—°ê²°
            for (i, (chunk_text, embedding_tuple)) in chunks.iter().zip(embeddings).enumerate() {
                let chunk_uuid = Uuid::new_v4().to_string();
                let vector: Vec<f32> = embedding_tuple.1.first().vec.iter().map(|&x| x as f32).collect();
                // Chunk ìƒì„±
                let chunk_record: Option<ChunkNode> = db
                    .create(("chunk", &chunk_uuid))
                    .content(ChunkNode {
                        id: None,
                        content: chunk_text.clone(),
                        embedding: vector, // rigì˜ Embedding êµ¬ì¡°ì²´ì—ì„œ ë²¡í„° ì¶”ì¶œ
                        page_index: i,
                    })
                    .await
                    .map_err(|e| e.to_string())?;
                
                let chunk_id = chunk_record.unwrap().id.unwrap();

                // [Edge] Document -> contains -> Chunk
                db.query("RELATE $doc->contains->$chunk")
                    .bind(("doc", doc_id.clone()))
                    .bind(("chunk", chunk_id))
                    .await
                    .map_err(|e| e.to_string())?
                    .check() // ìˆ˜ì •ë¨
                    .map_err(|e| e.to_string())?;
            }

            processed_count += 1;
        }
    }

    Ok(format!("{}ê°œì˜ PDF íŒŒì¼ì´ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤(SurrealDB)ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", processed_count))
}

// ---------------------------------------------------------
// Command : ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
// ---------------------------------------------------------
#[tauri::command]
async fn download_model(app_handle: tauri::AppHandle, url: String, filename: String) -> Result<String, String> {
    eprintln!("ğŸš€ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ìˆ˜ì‹ : {} -> {}", url, filename);
    
    // ëª¨ë¸ì´ ì €ì¥ë  í´ë” ê²½ë¡œ (src-tauri/models)
    let model_dir = app_handle.path().resource_dir().unwrap().join("models");
    
    // í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if !model_dir.exists() {
        std::fs::create_dir_all(&model_dir).map_err(|e| e.to_string())?;
    }

    // ì—¬ê¸°ì— ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë¡œì§ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤. (í˜„ì¬ëŠ” ì„±ê³µ ë©”ì‹œì§€ë§Œ ë°˜í™˜)
    // ì‹¤ì œ êµ¬í˜„ì€ reqwest ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.
    
    Ok(format!("{} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ (ê²½ë¡œ: {:?})", filename, model_dir))
}

// ---------------------------------------------------------
// Main
// ---------------------------------------------------------
#[tokio::main]
async fn main() {
    dotenv().ok();

    // 1. SurrealDB ì´ˆê¸°í™” (ë¡œì»¬ íŒŒì¼ rocksdb ì‚¬ìš©)
    // ì•± ì‹¤í–‰ ê²½ë¡œì˜ 'crisper.db' í´ë”ì— ì €ì¥ë¨
    let db = Surreal::new::<RocksDb>("../data/crisper_db").await.expect("DB ìƒì„± ì‹¤íŒ¨");
    
    // ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ DB ì„ íƒ
    db.use_ns("crisper_ns").use_db("crisper_db").await.expect("DB ì„ íƒ ì‹¤íŒ¨");

    let openai_client = Client::from_env();

    let app_state = AppState {
        db,
        openai_client,
    };

    let llama_child = Arc::new(Mutex::new(None::<CommandChild>));
    let llama_child_clone = llama_child.clone();

    let app = tauri::Builder::default()
        .plugin(tauri_plugin_shell::init())
        .plugin(tauri_plugin_dialog::init())
        .manage(app_state)
        .invoke_handler(tauri::generate_handler![
            process_pdfs_graph, // ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜
            fetch_graph_data,   // ê·¸ë˜í”„ ì‹œê°í™” í•¨ìˆ˜
        ])
        .setup(move |app| {
            // --- ì‚¬ì´ë“œì¹´ ì‹¤í–‰ ë¡œì§ ---
            let resource_path = app.path().resource_dir().unwrap().join("binaries");
            
            // ëª¨ë¸ ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
            let model_path = "C:/eoraha/crisper_app/crisper-app/src-tauri/models/ggml-model-Q4_K_M.gguf";

            let sidecar_command = app.shell().sidecar("llama-server").unwrap()
                .current_dir(resource_path)
                .args([
                    "--model", model_path,
                    "--port", "8080",
                    "--host", "127.0.0.1",
                    "--ctx-size", "4096",
                    "--parallel", "1",
                    "--n-gpu-layers", "99"
                ]);

            // [ë³€ê²½] spawn ì‹œ child í”„ë¡œì„¸ìŠ¤ í•¸ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            let (mut rx, child) = sidecar_command.spawn().expect("ì‚¬ì´ë“œì¹´ ì‹¤í–‰ ì‹¤íŒ¨");

            // [ì¶”ê°€] í•¸ë“¤ì„ ê³µìœ  ë³€ìˆ˜ì— ì €ì¥
            *llama_child_clone.lock().unwrap() = Some(child);

            // ë¡œê·¸ ì¶œë ¥ìš© ë¹„ë™ê¸° íƒœìŠ¤í¬
            tauri::async_runtime::spawn(async move {
                while let Some(event) = rx.recv().await {
                    if let tauri_plugin_shell::process::CommandEvent::Stderr(line) = event {
                         if let Ok(text) = String::from_utf8(line) {
                             // ë¡œê·¸ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬
                             // println!("LLAMA: {}", text.trim());
                         }
                    }
                }
            });
            
            Ok(())
        })
        .build(tauri::generate_context!())
        .expect("ì•± ë¹Œë“œ ì˜¤ë¥˜");

    // 3. ì•± ì‹¤í–‰ ë° ì¢…ë£Œ ì´ë²¤íŠ¸ í•¸ë“¤ë§ (Run Loop)
    app.run(move |_app_handle, event| {
        match event {
            // ì•±ì´ ì™„ì „íˆ ì¢…ë£Œë  ë•Œ (ì°½ì„ ë‹«ê±°ë‚˜ Quit í–ˆì„ ë•Œ)
            RunEvent::Exit => {
                println!("ğŸ›‘ ì•± ì¢…ë£Œ ê°ì§€. Llama Serverë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...");
                
                // ê³µìœ  ë³€ìˆ˜ì—ì„œ í”„ë¡œì„¸ìŠ¤ í•¸ë“¤ì„ êº¼ë‚´ì„œ kill() í˜¸ì¶œ
                let mut child_guard = llama_child.lock().unwrap();
                if let Some(child) = child_guard.take() {
                    // kill()ì„ í˜¸ì¶œí•˜ì—¬ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
                    if let Err(e) = child.kill() {
                        eprintln!("âš ï¸ Llama Server ì¢…ë£Œ ì‹¤íŒ¨: {}", e);
                    } else {
                        println!("âœ… Llama Serverê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
                    }
                }
            }
            _ => {}
        }
    });
}