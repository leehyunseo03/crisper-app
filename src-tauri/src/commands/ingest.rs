// src-tauri/src/commands/ingest.rs
use tauri::State;
use std::path::Path;
use std::fs;
use uuid::Uuid;
use chrono::Utc;
use surrealdb::engine::local::Db;
use surrealdb::Surreal;
use rig::embeddings::EmbeddingsBuilder;
use rig::client::EmbeddingsClient;

use crate::models::{EventNode, DocumentNode, ChunkNode};
use crate::utils::{extract_text_from_pdf, chunk_text, RigDoc};
use crate::llm::extractor::extract_knowledge;
use crate::AppState;

#[tauri::command]
pub async fn process_pdfs(
    path: String,
    state: State<'_, AppState>,
) -> Result<String, String> {
    let db = &state.db;
    // [ì¤‘ìš”] ì„ë² ë”©ìš© í´ë¼ì´ì–¸íŠ¸ (8080)
    let embed_model = state.embed_client.embedding_model("ggml-model-Q4_K_M");
    
    // [ì¤‘ìš”] ì¶”ì¶œìš© í´ë¼ì´ì–¸íŠ¸ (8081)
    let gen_client = &state.gen_client;

    println!("ğŸ“‚ Ingesting from: {}", path);

    // 1. ì„¸ì…˜(Event) ìƒì„±
    let session_id = Uuid::new_v4().to_string();
    let event: EventNode = db.create(("event", &session_id))
        .content(EventNode {
            id: None,
            summary: format!("Import from {}", path),
            created_at: Utc::now(),
        })
        .await
        .map_err(|e| e.to_string())?
        .ok_or("Failed to create event")?;

    let entries = fs::read_dir(path).map_err(|e| e.to_string())?;

    for entry in entries {
        let path = entry.map_err(|e| e.to_string())?.path();
        if path.extension().and_then(|s| s.to_str()) != Some("pdf") { continue; }
        
        let filename = path.file_name().unwrap().to_string_lossy().to_string();
        
        // 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ & ì²­í‚¹
        let text = extract_text_from_pdf(&path).map_err(|e| e.to_string())?;
        if text.trim().is_empty() { continue; }
        let chunks = chunk_text(&text, 1000, 100);

        // 3. Document ìƒì„±
        let doc_id = Uuid::new_v4().to_string();
        let _doc: DocumentNode = db.create(("document", &doc_id))
            .content(DocumentNode { 
                id: None, filename: filename.clone(), 
                created_at: Utc::now(), metadata: Default::default() 
            })
            .await
            .map_err(|e| e.to_string())?
            .ok_or("Failed to create event")?;

        // Event -> Document ì—°ê²°
        let _ = db.query("RELATE $e->imported->$d")
            .bind(("e", session_id.clone())).bind(("d", format!("document:{}", doc_id)))
            .await.map_err(|e| e.to_string())?;

        // 4. ì„ë² ë”© ìƒì„± (Batch)
        /*
        let rig_docs: Vec<RigDoc> = chunks.iter().map(|c| RigDoc { id: "x".into(), content: c.clone() }).collect();
        let embeddings = EmbeddingsBuilder::new(embed_model.clone())
            .documents(rig_docs).map_err(|e| e.to_string())?
            .build().await.map_err(|e| e.to_string())?;
        */

        // 5. Chunk ì €ì¥ ë° ì§€ì‹ ì¶”ì¶œ ë£¨í”„
        //for (i, (txt, emb_res)) in chunks.iter().zip(embeddings).enumerate() {
        for (i, txt) in chunks.iter().enumerate(){
            let chunk_uuid = Uuid::new_v4().to_string();
            //let vec: Vec<f32> = emb_res.1.first().vec.iter().map(|&x| x as f32).collect();
            let dummy_embedding: Vec<f32> = vec![];

            let _chunk: ChunkNode = db.create(("chunk", &chunk_uuid))
                .content(ChunkNode {
                    id: None, 
                    content: txt.clone(), 
                    page_index: i, 
                    embedding: dummy_embedding//vec.clone()
                })
                .await
                .map_err(|e| e.to_string())?
                .ok_or("Failed to create event")?;

            // Document -> Chunk ì—°ê²°
            db.query("RELATE $d->contains->$c")
                .bind(("d", format!("document:{}", doc_id)))
                .bind(("c", format!("chunk:{}", chunk_uuid)))
                .await.map_err(|e| e.to_string())?;
            
            let gen_url = "http://127.0.0.1:8081/v1"; 

            // ğŸ§  ì§€ì‹ ì¶”ì¶œ
            if i < 10 { // í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 10ê°œ ì²­í¬ë§Œ
                println!("ğŸ¤– Extracting info from chunk {} of {}...", i, filename);
                
                // ì§ì ‘ í˜¸ì¶œí•œ extractor í•¨ìˆ˜ ì‚¬ìš©
                match extract_knowledge(gen_url, txt).await {
                    Ok(result) => {
                        println!("  âœ… Found {} entities, {} relations", result.entities.len(), result.relations.len());
                        
                        // TODO: ì¶”ì¶œëœ entityì™€ relationì„ DBì— ì €ì¥í•˜ëŠ” ë¡œì§ ì¶”ê°€
                        // ì˜ˆ: save_graph_data(&db, doc_id, result).await;
                    },
                    Err(e) => {
                        println!("  âŒ Extraction failed: {}", e);
                        // ì—ëŸ¬ê°€ ë‚˜ë„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ëŠ” ì£½ì§€ ì•Šë„ë¡ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
                    }
                }
            }
        }
    }

    Ok("Done".to_string())
}